[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Practical Bayesian Extremist",
    "section": "",
    "text": "This is a dummy blog posts\n\n\n\n\n\n\n123\n\n\nSecond Tag\n\n\n\nThis is a test post. In this post, I try out different functionalities\n\n\n\n\n\nMar 10, 2024\n\n\n4 min\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 7, 2024\n\n\n1 min\n\n\n\n\n\n\n\n시계열 평활기법\n\n\n\n\n\n\nBayesian smoothing\n\n\n\n시계열 평활기법에 대한 입문\n\n\n\n\n\nOct 4, 2022\n\n\n3 min\n\n\n\n\n\n\n\n베이지안 평활기법\n\n\n\n\n\n\nBayesian smoothing\n\n\n\nBayesian smoothing 기법에 대한 소개\n\n\n\n\n\nOct 4, 2022\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/smoothing/smoothing1.html",
    "href": "posts/smoothing/smoothing1.html",
    "title": "시계열 평활기법",
    "section": "",
    "text": "1. 시계열 평활기법\n이번 절에서는 전통적인 시계열 평활화 문제를 살펴본다. 전통적인 시계열 평활화는 관측값(종속변수)가 정규 분포를 따르는 시계열 자료의 경우 연속하는 추세값의 차이에 벌점을 부여하여 매끄러운 추세를 예측하는 방법을 말한다. 그 다음 전통적 평활화 기법이 추세에 대한 확률보행 사전분포를 부여한 다음 사후분포를 구하여 얻은 베이지안 평활화 기법에서의 평균과 밀접한 관계가 있음을 보이고자 한다.\n벡터 \\(\\mathbf y=(y_1,\\ldots, y_T)\\)가 동일한 간격으로 관측된 시계열 자료라고 가정하자. 즉,\n\\[\ny_t=\\mu_t+\\varepsilon_t,\\quad t=1,\\ldots, T\n\\]\n여기서 \\(\\boldsymbol\\mu=(\\mu_1,\\ldots, \\mu_T)\\) 는 시계열의 내재적인 추세를, \\(\\boldsymbol\\varepsilon=(\\varepsilon_1,\\ldots,\\varepsilon_T)\\) 를 \\(E(\\varepsilon_t)=0,\\;\\forall t\\) 를 만족하는 독립인 오차항을 나타낸다.\nWhittaker는 다음과 같이 벌점최소제곱 (penalised least square; PLS) 기준을 최소하는 방법으로 \\(\\boldsymbol\\mu\\) 를 추정하였다. \\[\n\\text{PLS}(\\boldsymbol \\mu)=\\sum_{t=1}^T (y_t-\\mu_t)^2+\\lambda\\sum_{t=3}^T (\\mu_t-2\\mu_{t-1}+\\mu_{t-2})^2\n\\] PLS를 최소화하기 위해서는 두 가지 요건을 동시에 만족해야 한다. 우선 추세 \\(\\mu_t\\) 가 해당 시점의 관측치 \\(y_t\\)와 가까워야 하고, 둘째 \\(t\\) 시점의 추세가 \\(t-1\\) 시점의 추세에서 크게 벗어나지 않고 매끄러워야 한다. 추세의 매끄러움은 시계열과 추세간 차이에 대한 최소제곱에 다음과 같이 벌점항을 추가하여 고려할 수 있다. \\[\n\\text{pen}(\\boldsymbol\\mu)=\\sum_{t=3}^T(\\mu_t-2\\mu_{t-1}+\\mu_{t-2})^2=\\sum_{t=3}^T(\\triangle^2\\mu_t)^2\n\\] 파라미터 \\(\\lambda\\) 는 두 가지 요건의 상충관계에서 어느쪽에 가중치를 둘 것인지를 결정한다. 여기서 오차항 \\(\\varepsilon_t\\) 가 독립이고, 모든 \\(t\\) 에 대하여 동일한 분산, \\(Var(\\varepsilon_t)=\\sigma^2\\) 이라고 가정한다. 일반적으로 \\(\\mu_t\\) 의 편차에 대한 \\(d\\) 차 벌점은 다음과 같이 정의한다. \\[\n\\text{pen}(\\boldsymbol\\mu) = \\sum_{t=d+1}^T (\\triangle^d\\mu_t)^2,\\quad \\triangle^d \\mu_t=\\triangle^{d-1}\\mu_t-\\triangle^{d-1}\\mu_{t-1}\n\\] \\(d=1\\) 인 경우 수평선 \\(\\mu_t=a\\) 로부터 편차에 대하여 벌점을 부과하고, \\(d=2\\) 인 경우 직선 \\(\\mu_t=a+bt\\) 로부터의 편차에 벌점을 부과한다. 일반적으로 \\(d\\) 차 벌점은 차수 \\(d-1\\) 차 다항식으로부터 편차에 대하여 벌점을 부과한다. 이제 벌점항을 행렬로 간단히 표기하는 법을 알아보자. \\(\\mu_1,\\ldots,\\mu_T\\) 에 대한 1차 차분 행렬은 다음과 같이 주어진다. \\[\n\\mathbf D_1^{(T-1)\\times T}=\\begin{pmatrix}-1& 1 &0& \\cdots& 0\\\\ \\vdots&-1&1&&\\vdots\\\\0&\\cdots&&-1&1\\\\\\end{pmatrix},\\qquad \\mathbf D_1^{(T-1)\\times T}\\boldsymbol\\gamma=\\begin{pmatrix}\\mu_2-\\mu_1 \\\\ \\cdots\\\\ \\mu_T-\\mu_{T-1}\\\\\\end{pmatrix}\n\\] 일반적인 고차 차분행렬은 다음 식을 이용하여 순차적으로 구할 수 있다. \\[\n\\mathbf D_d^{(T-d)\\times T}=\\mathbf D_1^{(T-d)\\times (T-d+1)}\\mathbf D_{d-1}^{(T-d+1)\\times T}\n\\] 예를 들어 2차 차분행렬은 \\(\\mathbf D_1^{(T-2)\\times (T-1)}\\times \\mathbf D_1^{(T-1)\\times T}\\) 로부터 \\[\n\\mathbf D_2^{(T-2)\\times T}=\\begin{pmatrix}1& -2 &1& &\\cdots& 0\\\\ &1&-2&1&\\\\\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\0 &&&1&-2&1\\\\\\end{pmatrix}\n\\] 이다. 이제 차분행렬 \\(D\\)로 부터 벌점행렬 \\(K\\) 를 구해보자. 벌점항을 다시 정리하면 \\[\n\\text{pen}(\\boldsymbol\\mu)=\\sum_{t=d+1}^T (\\triangle^d\\mu_t)^2=\\boldsymbol\\mu \\mathbf D_d'\\mathbf D_d\\boldsymbol\\mu=\\boldsymbol\\mu \\mathbf K_d \\boldsymbol\\mu\n\\] 여기서 \\(\\mathbf K_d=\\mathbf D_d'\\mathbf D_d\\) 로 \\(T\\times T\\) 차원의 벌점행렬을 만든다. 1차 벌점행렬과 2차 벌점행렬을 구하면 다음과 같다. \\[\n\\small\n\\mathbf K_1 = \\begin{pmatrix}1&-1&&&\\cdots&0\\\\-1&2&-1&&\\cdots&0\\\\0&-1&2&-1&\\cdots&0\\\\\\vdots&&&\\ddots&\\ddots&\\vdots\\\\0&0&\\cdots&-1&2&-1\\\\ 0&0&\\cdots&0&-1&1\\end{pmatrix},\\qquad \\mathbf K_2=\\begin{pmatrix}1&-2&1&&&\\cdots&0\\\\-2&5&-4&1&&\\cdots&0\\\\1&-4&6&-4&1&\\cdots&0\\\\\\vdots&&&\\ddots&\\ddots&&\\vdots\\\\0&0&\\cdots&1&-4&5&-2\\\\ 0&0&\\cdots&&1&-2&1\\end{pmatrix}\n\\]\n벌점행렬의 랭크는 \\(rank(\\mathbf K_d)=T-d\\) 로 완전한 랭크를 갖지 않는다. 따라서, 벌점을 적용받지 않는 \\(d-1\\)차까지의 다항식은 \\(\\mathbf K_d\\) 의 널공간을 형성한다. 이제 모형을 행렬과 벡터를 이용하여 다시 정의하자. \\[\n\\text{PLS}(\\boldsymbol\\mu)=(\\mathbf y-\\boldsymbol\\mu)'(\\mathbf y-\\boldsymbol\\mu)+\\lambda\\boldsymbol\\mu'\\mathbf K\\boldsymbol\\mu = \\mathbf y '\\mathbf y -2\\boldsymbol\\mu'\\mathbf y+\\boldsymbol\\mu'(\\mathbf I +\\lambda\\mathbf K)\\boldsymbol\\mu\n\\] 최소제곱기준을 만족시키는 \\(\\boldsymbol\\mu\\)를 구하면 \\[\n\\frac{\\partial \\text{PLS}(\\boldsymbol\\mu)}{\\partial\\boldsymbol\\mu}=-2\\mathbf y + 2(\\mathbf I +\\lambda \\mathbf K )\\boldsymbol\\mu=0\\quad \\Rightarrow\\quad \\hat{\\boldsymbol\\mu}=(I+\\lambda \\mathbf K)^{-1}\\mathbf y\n\\] PLS 추정량은 능형회귀 (ridge shrinkage) 추정량과 동일한 구조를 갖는데, 관측치 \\(y\\) 를 부드러운 추세 \\(\\mu\\)의 값으로 끌어 당기는 현상이 나타난다. PLS 추정량의 기대값과 분산은 다음과 같다.\n\n\\(E(\\hat{\\boldsymbol\\mu})=E[(\\mathbf I +\\lambda \\mathbf K)^{-1}\\mathbf y)=(\\mathbf I+\\lambda\\mathbf K)^{-1}\\boldsymbol\\mu,\\) 즉 PLS 추정량은 편차 추정량이다.\n오차항을 i.i.d.라 가정하면 분산은 \\(Cov(\\hat{\\mathbf\\mu})=(\\mathbf I+\\lambda\\mathbf K)^{-1}Cov(\\mathbf y)(\\mathbf I+\\lambda\\mathbf K)^{-1}=\\sigma^2(\\mathbf I+\\lambda\\mathbf K)^{-1}\\)\n\nPLS 추정치는 분산을 줄임으로써 평균제곱오차(mean squared error; MSE)를 감소시킨다. \\(\\lambda\\)의 값이 작으면 편차가 작아지지만 변동성이 크고, \\(\\lambda\\)의 값이 크면 변동성은 적지만 편차가 커진다. 마지막으로 오차가 iid인 가우스 분포를 따른다고 하면, 즉 \\(\\varepsilon_t\\sim N(0,\\sigma^2)\\) 이면 PLS 추정량의 분포는 다음과 같다. \\[\n\\hat{\\boldsymbol\\mu}\\sim N((\\mathbf I+\\lambda\\mathbf K)^{-1}\\mathbf y,\\sigma^2(I+\\lambda\\mathbf K)^{-2})\n\\]"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "CV_ENG.html",
    "href": "CV_ENG.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Education\nDoctor of Philosohpy in Statistics, University of Edinburgh, UK,  “Bayesian analysis of non-stationary extremes”, 2022.\nMaster of Science in Statistics & Oprerational Research, University of Edinburgh,  UK, “A primer on Benford’s Law”, 2017.\nMaster of Arts in Economics, Yonsei University, South Korea,  “A study on the won/dollar exchange rate in the short and long run: comparing the time and frequency domain approaches”, 2003.\nBachelor of Laws, Korea National Open University, South Korea, 2010.  Bachelor of Arts in Economics, Yonsei University, South Korea, 2001.\n\n\nPublications\nLee, J., de Carvalho, M., Rua, A. & Avila, J. (2024). Bayesian smoothing for time‑varying extremal dependence. Journal of the Royal Statistical Society: Series C, qlae002.\nLee, J., Kim, J. & Choi, K. (2023). Joint climate stress-test, FSS working paper 2023-1.\nYoon, Y., Lee, J., & Hwang, J. (2023). A study on the relationship between corporate carbon emissions and stock market returns. Journal of Financial Regulation and Supervision, 10(2), 1–44.\nLee, J. & de Carvalho, M. (2019). Technological improvements or climate change? Bayesian modeling of time‑varying conformance to Benford’s Law. Plos One, 14(4), e0213300.\n\n\nTalks/Posters\nLee, Junho (2024), “Stress-testing & other macroprudential supervision techniques in the Financial Supervisory Service”, a talk at NFSC-KOICA international conference, ‘Vietnam’s financial market: Opportunities and challenges’, Dec 2023, Dalat, Vietnam.\nLee, J., & Kim, J. (2023). “Climate stress‑testing for banking and insurance sectors in South Korea”. a talk at SPGMI_KPMG Webinar, March 2023, on‑line.\nLee, J., & de Carvalho, M. (2021). “Bayesian Semiparametric Inferences for Covariate‑adjusted Extreme‑value Copula with application to Cryptocurrency Markets”. a talk at XXV Congress of the Portuguese Statistical Society, November 2021, Portugal.\nLee, J., de Carvalho, M., & Rua, A. (2021). “Bayesian smoothing of time‑varying extremal dependence in international stock markets”. a talk at Eco‑stats 2021, June 2021, Hong Kong.\nLee, J., de Carvalho, M. & Rua, A. (2019). “Bayesian semiparametric regression for heavy‑tailed responses”. a talk at CMstatistics 2019, 14‑16 December 2019, London, UK.\nLee, J., de Carvalho, M. & Rua, A. (2019). “Bayesian semi‑parametric modelling of heteroscedastic extremes”. a talk at Extreme Value Analysis 2019, July 2019, Zagreb, Croatia.\nLee, J., de Carvalho, M. & Rua, A. (2019). “What hides behind an extreme currency demand? Bayesian semi‑parametric modelling of heteroscedastic extremes”. a poster at Centre for Statistics conference, June 2019, Edinburgh, UK.\nLee, J., & de Carvalho, M. (2018). “Modelling Time‑Varying Conformance to Benford’s Law”. a poster at ISBA 2018 World meeting, June 2018, Edinburgh, UK.\n\n\nWork Experience\nFinancial Supervisory Service : Lead manager\nDeveloping fraud detection models in stock markets, 2014 – present.  Stress‑testing of financial companies and scenario analysis of climate‑change, 2021 – 2023. Leave for academic training, 2016 – 2020. Investigating market frauds in capital markets, 2013 – 2016. Examining financial investment companies, 2010 – 2013. Investigating market frauds in stock and derivative markets, 2007 – 2010. Inspecting corporate disclosure reports, 2005 – 2007. Developing on‑site examinaion techniques, 2003 – 2005."
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "This is a dummy blog posts\n\n\n\n\n\n\n\n\nMar 10, 2024\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nMar 7, 2024\n\n\n\n\n\n\n\n시계열 평활기법\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n베이지안 평활기법\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practical Bayesian Extremist",
    "section": "",
    "text": "블로그에 오신 걸 환영합니다.\n금융감독원에서 베이지안 통계학을 연구하고 응용하는 이준호입니다.\n젊은 시절 경제학과 법학을 공부하였으나, 2010년 중반 데이터 혁명과 기계학습에 감명받아 뒤늦은 40대에 유학길에 올라 영국 에든버러대학교(University of Edinburgh) 평소 관심이 있던 베이즈 통계학(Bayesian statistics)을 공부였습니다.\n극단값 이론과(Extreme value theory) 베이즈비모수통계학(Nonparametric Bayes)을 전공하였고, R 언어를 이용한 실용적인 데이터 분석 패키지 개발과 통계학과 머신러닝 모형의 수학적 배경에 관심을 갖고 있습니다.\n유학 이후 금융감독원에서 거시경제 및 기후경제모형 모델링, 금융산업과 금융회사에 대한 스트레스 테스트 업무를 주로 담당했었고, 현재는 증권 불공정거래 탐색 및 자금추적 모형을 개발하고 있습니다\nHi, I’m Junho Lee, a Bayesian statistician and R programmer.\nI have a PhD in Statistics from the University of Edinburgh and work for the Financial Supervisory Service in South Korea.\nI have worked on various macroeconomic modelling including climate scenario analysis, as well as conducting stress-testing over financial institutions in South Korea.\nMy current interest is on developing fraud detection models in stock market and applying Bayesian networks to account tracking."
  },
  {
    "objectID": "CV_KOR.html",
    "href": "CV_KOR.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Education\n영국 에든버러 통계학 박사, 2022.  학위논문: “Bayesian analysis of non-stationary extremes”\n영국 에든버러대학교 통계학·OR 석사 2017.  학위논문: “A primer on Benford’s Law”\n연세대학교 경제학 석사, 2003. 학위논문: “장단기 원/달러 환율에 대한 연구: Time-domain과 Frequency-domain 비교”\n한국방송통신대학교 법학사 2010.  연세대학교 경제학사 2001.\n\n\nPublications\nLee, J., de Carvalho, M., Rua, A. & Avila, J. (2024). Bayesian smoothing for time‑varying extremal dependence. Journal of the Royal Statistical Society: Series C, qlae002.\n이준호·김정일·최광신 (2023). 금융권 공동 기후 스트레스테스트, FSS working paper 2023-1.\n윤양인·이준호·황재학,(2023). 기업의 탄소배출과 주가수익률간 관계에 관한 연구. 금융감독연구, 10(2), 1-44..\nLee, J. & de Carvalho, M. (2019). Technological improvements or climate change? Bayesian modeling of time‑varying conformance to Benford’s Law. Plos One, 14(4), e0213300.\n\n\nTalks/Posters\nLee, Junho (2024), “Stress-testing & other macroprudential supervision techniques in the Financial Supervisory Service”, a talk at NFSC-KOICA international conference, ‘Vietnam’s financial market: Opportunities and challenges’, Dec 2023, Dalat, Vietnam.\n이준호·김정일(2023). “금융감독기관의 기후스트레스테스트 진행현황 및 향후계획”. SPGMI-KPMG 웹비나, 2023.3.\nLee, J., & de Carvalho, M. (2021). “Bayesian Semiparametric Inferences for Covariate‑adjusted Extreme‑value Copula with application to Cryptocurrency Markets”. a talk at XXV Congress of the Portuguese Statistical Society, November 2021, Portugal.\nLee, J., de Carvalho, M., & Rua, A. (2021). “Bayesian smoothing of time‑varying extremal dependence in international stock markets”. a talk at Eco‑stats 2021, June 2021, Hong Kong.\nLee, J., de Carvalho, M. & Rua, A. (2019). “Bayesian semiparametric regression for heavy‑tailed responses”. a talk at CMstatistics 2019, 14‑16 December 2019, London, UK.\nLee, J., de Carvalho, M. & Rua, A. (2019). “Bayesian semi‑parametric modelling of heteroscedastic extremes”. a talk at Extreme Value Analysis 2019, July 2019, Zagreb, Croatia.\nLee, J., de Carvalho, M. & Rua, A. (2019). “What hides behind an extreme currency demand? Bayesian semi‑parametric modelling of heteroscedastic extremes”. a poster at Centre for Statistics conference, June 2019, Edinburgh, UK.\nLee, J., & de Carvalho, M. (2018). “Modelling Time‑Varying Conformance to Benford’s Law”. a poster at ISBA 2018 World meeting, June 2018, Edinburgh, UK.\n\n\nWork Experience\n금융감독원 : 수석조사역\n불공정거래 조사 및 시세조종탐지/자금추적 모형 개발 (조사2국), 2024 – 현재.  스트레스테스트 및 기후시나리오 분석 (금융시장안정국), 2021 – 2023. 불공정거래 조사·기획 (조사1국), 2013 – 2016. 금융투자회사 검사(금융투자서비스국·금융투자검사국), 2010 – 2013. 파생상품·증권 불공정거래조사 (조사1·2국), 2007 – 2010. 지분공시 심사(공시감독국), 2005 – 2007. 검사제도·기획 (검사총괄국), 2003 – 2005."
  },
  {
    "objectID": "posts/demo/post.html",
    "href": "posts/demo/post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/demo/post.html#merriweather",
    "href": "posts/demo/post.html#merriweather",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nglm.mod &lt;- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds &lt;- dat %&gt;% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit &gt; 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %&gt;% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]"
  },
  {
    "objectID": "posts/demo/post.html#columns",
    "href": "posts/demo/post.html#columns",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "geom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)"
  },
  {
    "objectID": "posts/demo/post.html#margin-captions",
    "href": "posts/demo/post.html#margin-captions",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "ggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/smoothing/smoothing2.html",
    "href": "posts/smoothing/smoothing2.html",
    "title": "베이지안 평활기법",
    "section": "",
    "text": "2. 베이지안 평활기법\n이제 시계열 자료에 대한 베이지안 입장에서 평활화에 대하여 살펴보자. 마찬가지로 시계열 자료에 내재된 추세를 확률벡터 \\(\\boldsymbol\\mu\\) 라 하고, 정규분포 관측모형을 가정하면 관측값 \\(\\mathbf y\\) 는 가우스 조건부 확률분포, \\[\n\\mathbf y \\mid \\boldsymbol \\mu \\sim N(\\boldsymbol\\mu, \\sigma^2\\mathbf I)\n\\] 를 따른다. 여기서 일단 \\(\\sigma^2\\) 가 알려져 있다고 가정하면, 관측치의 우도함수는 다음과 같다. \\[\np(\\mathbf y\\mid \\boldsymbol\\mu)\\propto \\exp\\left\\{-\\frac{1}{2\\sigma^2}(\\mathbf y-\\boldsymbol \\mu)'(\\mathbf y-\\boldsymbol\\mu)\\right\\}.\n\\]\n이제 \\(\\boldsymbol\\mu\\) 에 대하여 사전분포 \\(p(\\boldsymbol\\mu)\\) 를 부여하는 방법에 대하여 알아보자. 2차 확률보행의 경우 \\(\\mu_t\\) 의 사전분포는 \\[\n\\mu_t=2\\mu_{t-1}-\\mu_{t-2}+u_t, \\quad u_t\\sim N(0,\\tau^2),\\quad t=3,\\ldots,T.\n\\] 여기서 \\(u_t\\) 는 분산이 \\(\\tau^2\\) 인 가우스 분포를 나타낸다. 초기값 \\(\\mu_1\\) 과 \\(\\mu_2\\) 에 대해서는 별도의 사전분포를 부여해야 하는데 우리는 각각각 다음과 같이 가우스 분포를 부여한다. \\[\n(\\mu_1,\\mu_2)\\sim N(0,c\\mathbf I_2)\n\\] 위 초기값에 해당하는 사전분포는 확률벡터 \\(\\boldsymbol\\mu\\) 에 대한 정규 결합 가우스 분포를 얻게 해주며, 확률보행 사전분포의 오차항과 독립이다. 또한 \\(c\\to\\infty\\) 이면, 위 사전분포는 평탄한 비정규분포, 즉 \\[\np(\\mu_1)\\propto \\text{상수},\\quad  p(\\mu_2)\\propto \\text{상수}\n\\] 가 되는데 이 경우 \\(\\boldsymbol\\mu\\) 의 결합 사전분포는 부분적으로 비정규인 가우스 분포이다.\n초기값 \\(\\mu_1\\) 과 \\(\\mu_2\\) 에 대하여 평탄한 사전분포를 가정하고, 확률벡터 \\(\\boldsymbol\\mu\\) 에 대한 결합 가우스 사전분포를 정리하면 \\[\np(\\boldsymbol\\mu)\\propto \\exp\\left(-\\frac{1}{2\\tau^2}\\boldsymbol\\mu'\\mathbf K \\boldsymbol \\mu\\right)\n\\]\n이고, 여기서 \\(\\mathbf K=\\mathbf K_2\\) 랭크가 \\(T-2\\) 인 벌점행렬이다. 즉, 확률벡터 \\(\\boldsymbol\\mu\\) 의 결합 사전분포는 정밀도 행렬이 \\(\\mathbf K_2/\\tau^2\\)이고, 특이 가우스 분포를 갖는다. 빈도주의 입장에서 벌점항은 베이지언 입장에서 음의 로그 사전분포와 (상수항 부분을 제외하고) 동일하다는 것을 알 수 있다.\n확률벡터 \\(\\boldsymbol\\mu\\) 의 사후분포는 베이즈 법칙으로부터 다음과 같이 도출한다. \\[\np(\\boldsymbol\\mu\\mid \\mathbf y)=\\frac{p(\\mathbf y\\mid \\boldsymbol\\mu)p(\\boldsymbol\\mu)}{p(\\mathbf y)}\\propto p(\\mathbf y\\mid \\mathbf \\mu)p(\\boldsymbol\\mu)\n\\]\n사후분포 \\(p(\\boldsymbol\\mu\\mid \\mathbf y)\\) 의 특징은 다음과 같다.\n\n두 분포 \\(p(\\mathbf y\\mid \\mathbf \\mu)\\) 과 \\(p(\\boldsymbol\\mu)\\) 가 가우스 분포이기 때문에 사후분포 또한 가우스 분포를 갖는다. 따라서 그 특징을 사후분포의 기대값 \\(E(\\boldsymbol\\mu\\mid \\mathbf y)\\)과 공분산 행렬 \\(Cov(\\boldsymbol\\mu\\mid \\mathbf y)\\) 만으로 묘사할 수 있다.\n사후분포의 기대값과 최빈값 (mode) 는 로그사후분포를 극대화하는 값이다. 즉, 가우스분포로부터 \\[\n\\log p(\\boldsymbol\\mu\\mid \\mathbf y)=\\log p(\\mathbf y\\mid \\boldsymbol\\mu)+\\log p(\\boldsymbol\\mu)\n\\]\n조건부 독립성 가정과 초기값에 대하여 평탄 사전분포를 가정하면 사후 최빈값은 다음 식을 최소화하는 \\(\\boldsymbol\\mu^*\\) 값이다. \\[\n\\boldsymbol\\mu^*=\\arg\\min_{\\boldsymbol\\mu}\\frac{1}{\\sigma^2}\\sum_{t=1}^T (y_t-\\mu_t)^2+\\frac{1}{\\tau^2}\\sum_{t=3}^T (\\mu_t-2\\mu_{t-1}+\\mu_{t-2})^2\n\\]\n평활화 파라미터 \\(\\tau^2\\) 와 분산 \\(\\sigma^2\\) 의 비율 \\(\\lambda=\\sigma^2/\\tau^2\\) 를 정의하면 \\(\\hat{\\boldsymbol\\mu}_{PLS}\\)와 \\(\\boldsymbol\\mu^*\\)은 동일하다.\n\n베이지안 접근법을 PLS 추정량과 비교하면 베이지안의 \\(p(\\boldsymbol\\mu\\mid \\mathbf y)\\) 사후분포가 아래와 같이 가우스분포로 귀결됨에 따라 \\[\n\\begin{align}\np(\\boldsymbol\\mu\\mid \\mathbf y)&\\propto p(\\mathbf y\\mid \\boldsymbol\\mu)p(\\boldsymbol\\mu)\\propto \\exp\\left(-\\frac{1}{2\\sigma^2}(\\mathbf y-\\boldsymbol\\mu)'(\\mathbf y-\\boldsymbol\\mu)\\exp\\right)\\exp\\left(-\\frac{1}{2\\tau^2}(\\boldsymbol\\mu)'\\mathbf K(\\boldsymbol\\mu)\\exp\\right)\\\\\n&\\propto \\exp\\left(-\\frac{1}{2}(\\boldsymbol\\mu-(\\mathbf I +\\lambda\\mathbf K )^{-1}\\mathbf y)'\\frac{1}{\\sigma^2}(\\mathbf I +\\lambda\\mathbf K)(\\boldsymbol\\mu-(\\mathbf I +\\lambda\\mathbf K )^{-1}\\mathbf y \\right)\\\\\n&\\Rightarrow\\quad  \\boldsymbol\\mu\\mid \\mathbf y \\sim N((\\mathbf I +\\lambda\\mathbf K)^{-1}\\mathbf y,\\sigma^2(\\mathbf I +\\lambda\\mathbf K)^{-1})\n\\end{align}\n\\] PLS 추정량이 사후분포의 최빈값 또는 사후분포의 기대값 \\(E(\\boldsymbol\\mu\\mid \\mathbf y)\\) 이 일치한다. 또한 이 결과는 어떤 임의의 \\(d\\) 차 확률보행 사전분포에 대해서도 성립하므로 벌점행렬 \\(\\mathbf K\\) 에 대해서도 유효하게 성립한다. 하지만, \\(p(\\boldsymbol\\mu\\mid \\mathbf y)\\) 사후분포의 공분산 행렬은 PLS 추정량의 공분산과 다르다. 즉, \\[\nCov(\\hat{\\boldsymbol\\mu})=\\sigma^2(\\mathbf I +\\lambda\\mathbf K)^{-2}\\neq\\sigma^2(\\mathbf I +\\lambda\\mathbf K)^{-1}=Cov(\\boldsymbol\\mu\\mid \\mathbf y)\n\\] 두 공분산의 차이는 양의 준정칙성을 갖는데, 이런 의미에서 사후분포의 공분산이 PLS 추정량의 공분산보다 크다고 할 수 있다. \\[\nCov(\\boldsymbol\\mu\\mid \\mathbf y) - Cov(\\hat{\\boldsymbol\\mu})=Cov(\\boldsymbol\\mu\\mid \\mathbf y) (\\mathbf I -(\\mathbf I +\\lambda\\mathbf K)^{-1})\n\\] 하지만, 위와 같은 전통적 PLS 추정량과 베이지안 접근법의 동일한 결과는 오직 점추정치에 한하여 성립할 뿐, 통계적 추정량의 측면에서는 전혀 다르다."
  }
]